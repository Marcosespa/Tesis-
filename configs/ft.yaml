base_model: "meta-llama/Llama-3.1-8B-Instruct"
method: lora
learning_rate: 2e-4
batch_size: 8
num_epochs: 3
max_seq_len: 2048
